{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data smells\n",
    "Any time you are given a dataset from anyone, you should immediately be suspicious. Is this data what I think it is? Does it include what I expect? Is there anything I need to know about it? Will it produce the information I expect?\n",
    "\n",
    "One of the first things you should do is give it the smell test. \n",
    "\n",
    "Failure to give data the smell test [can lead you to miss stories and get your butt kicked on a competitive story](https://source.opennews.org/en-US/learning/handling-data-about-race-and-ethnicity/).\n",
    "\n",
    "Let's look at some campus crime data. You can [get it here](https://www.dropbox.com/s/avt894qyqhs1gp1/unlcrime.csv?dl=0) or find it in the Data folder in the class GitHub repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import agate\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "unlcrimes = agate.Table.from_csv('../../Data/unlcrime.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With data smells, we're trying to find common mistakes in data. [For more on data smells, read the GitHub wiki post that started it all](https://github.com/nikeiubel/data-smells/wiki/Ensuring-Accuracy-in-Data-Journalism). The common mistakes we're looking for are:\n",
    "\n",
    "* Missing data\n",
    "* Gaps in data\n",
    "* Wrong type of data\n",
    "* Outliers \n",
    "* Sharp curves\n",
    "* Conflicting information within a dataset\n",
    "* Conflicting information across datasets\n",
    "* Wrongly derived data\n",
    "* External inconsistency\n",
    "* Wrong spatial data\n",
    "* Unusuable data, including non-standard abbreviations, ambigious data, extraneous data, inconsistent data\n",
    "\n",
    "Not all of these data smells are detectable in code. You may have to ask people about the data. You may have to compare it to another dataset yourself. Does the agency that uses the data produce reports from the data? Does your analysis match those reports? That will expose wrongly derived data, or wrong units, or mistakes you made with inclusion or exclusion. \n",
    "\n",
    "But with several of these data smells, we can do them first, before we do anything else. First, let's look at **Wrong Type Of Data**. We can sniff that out by simply printing the table structure that Agate has discovered for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| column         | data_type |\n",
      "| -------------- | --------- |\n",
      "| Case #         | Text      |\n",
      "| Incident Code  | Text      |\n",
      "| Reported       | DateTime  |\n",
      "| Case Status    | Text      |\n",
      "| Start Occurred | DateTime  |\n",
      "| End Occurred   | DateTime  |\n",
      "| Building       | Text      |\n",
      "| Location       | Text      |\n",
      "| Stolen         | Number    |\n",
      "| Damaged        | Number    |\n",
      "| Description    | Text      |\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(unlcrimes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this, things seem to be good. Case #, because it has number in the name, might tempt you to think it's a number, but it's not anything you're going to do math on, so it's text. Dates appear to be dates, things that aren't numbers appear to be text, and the two dollar figures appear to be counted as numbers. That's a good start.\n",
    "\n",
    "The second smell we can find in Agate is Missing Data. We can do that through a series of Group By and Count steps. Let's start with Incident Codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "codes = unlcrimes.group_by('Incident Code')\n",
    "code_counts = codes.aggregate([\n",
    "    ('count', agate.Count())\n",
    "])\n",
    "\n",
    "# We need to sort it in descending order, z to a, becase Agate interprets blanks as after z\n",
    "code_counts = code_counts.order_by('Incident Code', reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Incident Code        | count |\n",
      "| -------------------- | ----- |\n",
      "|                      |     1 |\n",
      "| WEAPONS вЂ“ OTHER    |    10 |\n",
      "| WEAPONS - ILLEGAL... |     1 |\n",
      "| WEAPONS - FELON I... |     3 |\n",
      "| WEAPONS - DISCHAR... |     3 |\n",
      "| WEAPONS - CONCEALED  |     7 |\n",
      "| WARRANT SERVICE      |     4 |\n",
      "| VANDALISM - OTHER    |   392 |\n",
      "| VANDALISM - BY GR... |   106 |\n",
      "| UNL POLICY VIOLAT... |    30 |\n",
      "| UNL POLICY VIOLAT... |    12 |\n",
      "| TRESPASSING          |   311 |\n",
      "| TRAFFIC - SUSPEND... |   707 |\n",
      "| TRAFFIC - OTHER      |    54 |\n",
      "| TRAFFIC - IMPROPE... |     2 |\n",
      "| TRAFFIC - DIRECTION  |     1 |\n",
      "| TELEPHONE - THREA... |    15 |\n",
      "| TELEPHONE - OTHER    |    56 |\n",
      "| TELEPHONE - OBSCE... |     6 |\n",
      "| SUSPICIOUS VEHICLE   |     1 |\n",
      "| ...                  |   ... |\n"
     ]
    }
   ],
   "source": [
    "code_counts.print_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And there's that last one. It's blank. There is missing data. But it's only 1 record of thousands, so it's not going to matter in the grand scheme. If that had been larger, we would have to do some more reporting.\n",
    "\n",
    "Let's now look at **Gaps in Data**. It's been my experience that gaps in data often have to do with time, so let's first look at crimes by year, so we can see if there's a year with big jumps in reported crime. You'd expect the number to change, but not by huge amounts. Huge change would indicate, more often than not, that the data is missing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "crimes_with_years = unlcrimes.compute([\n",
    "    ('reported_year', agate.Formula(agate.Text(), lambda row: '%s' % row['Reported'].year))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| reported_year | count |\n",
      "| ------------- | ----- |\n",
      "| 2010          |   185 |\n",
      "| 2011          | 1,948 |\n",
      "| 2012          | 1,881 |\n",
      "| 2013          | 2,052 |\n",
      "| 2014          | 1,920 |\n",
      "| 2015          | 1,750 |\n"
     ]
    }
   ],
   "source": [
    "years = crimes_with_years.group_by('reported_year')\n",
    "year_counts = years.aggregate([\n",
    "    ('count', agate.Count())\n",
    "])\n",
    "year_counts.print_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, something doesn't look right here. 185 crimes in 2010? Not likely. And what about 2015? A ~200 incident drop wouldn't be *that* unheard of -- look at 2012 to 2013 -- but I'm suspicious. Did we get the whole of 2015? Let's check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "crimes_with_monthyears = unlcrimes.compute([\n",
    "    ('reported_monthyear', agate.Formula(agate.Text(), lambda row: '%s/%s' % (row['Reported'].month, row['Reported'].year)))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reported_monthyear count\n",
      "11/2010               56 ▓░░░░░░                            \n",
      "12/2010              129 ▓░░░░░░░░░░░░░░░                   \n",
      "1/2011               157 ▓░░░░░░░░░░░░░░░░░░                \n",
      "2/2011               168 ▓░░░░░░░░░░░░░░░░░░░               \n",
      "3/2011               157 ▓░░░░░░░░░░░░░░░░░░                \n",
      "4/2011               184 ▓░░░░░░░░░░░░░░░░░░░░░             \n",
      "5/2011               130 ▓░░░░░░░░░░░░░░░                   \n",
      "6/2011               124 ▓░░░░░░░░░░░░░░                    \n",
      "7/2011               137 ▓░░░░░░░░░░░░░░░░                  \n",
      "8/2011               183 ▓░░░░░░░░░░░░░░░░░░░░░             \n",
      "9/2011               242 ▓░░░░░░░░░░░░░░░░░░░░░░░░░░░       \n",
      "10/2011              175 ▓░░░░░░░░░░░░░░░░░░░░              \n",
      "11/2011              179 ▓░░░░░░░░░░░░░░░░░░░░              \n",
      "12/2011              112 ▓░░░░░░░░░░░░░                     \n",
      "1/2012               194 ▓░░░░░░░░░░░░░░░░░░░░░░            \n",
      "2/2012               147 ▓░░░░░░░░░░░░░░░░░                 \n",
      "3/2012               167 ▓░░░░░░░░░░░░░░░░░░░               \n",
      "4/2012               182 ▓░░░░░░░░░░░░░░░░░░░░░             \n",
      "5/2012               121 ▓░░░░░░░░░░░░░░                    \n",
      "6/2012               137 ▓░░░░░░░░░░░░░░░░                  \n",
      "7/2012               109 ▓░░░░░░░░░░░░                      \n",
      "8/2012               128 ▓░░░░░░░░░░░░░░░                   \n",
      "9/2012               226 ▓░░░░░░░░░░░░░░░░░░░░░░░░░░        \n",
      "10/2012              173 ▓░░░░░░░░░░░░░░░░░░░░              \n",
      "11/2012              173 ▓░░░░░░░░░░░░░░░░░░░░              \n",
      "12/2012              124 ▓░░░░░░░░░░░░░░                    \n",
      "1/2013               149 ▓░░░░░░░░░░░░░░░░░                 \n",
      "2/2013               163 ▓░░░░░░░░░░░░░░░░░░                \n",
      "3/2013               161 ▓░░░░░░░░░░░░░░░░░░                \n",
      "4/2013               176 ▓░░░░░░░░░░░░░░░░░░░░              \n",
      "5/2013               136 ▓░░░░░░░░░░░░░░░                   \n",
      "6/2013               117 ▓░░░░░░░░░░░░░                     \n",
      "7/2013               116 ▓░░░░░░░░░░░░░                     \n",
      "8/2013               204 ▓░░░░░░░░░░░░░░░░░░░░░░░           \n",
      "9/2013               272 ▓░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░   \n",
      "10/2013              214 ▓░░░░░░░░░░░░░░░░░░░░░░░░          \n",
      "11/2013              203 ▓░░░░░░░░░░░░░░░░░░░░░░░           \n",
      "12/2013              141 ▓░░░░░░░░░░░░░░░░                  \n",
      "1/2014               176 ▓░░░░░░░░░░░░░░░░░░░░              \n",
      "2/2014               157 ▓░░░░░░░░░░░░░░░░░░                \n",
      "3/2014               153 ▓░░░░░░░░░░░░░░░░░                 \n",
      "4/2014               203 ▓░░░░░░░░░░░░░░░░░░░░░░░           \n",
      "5/2014               157 ▓░░░░░░░░░░░░░░░░░░                \n",
      "6/2014               109 ▓░░░░░░░░░░░░                      \n",
      "7/2014               108 ▓░░░░░░░░░░░░                      \n",
      "8/2014               177 ▓░░░░░░░░░░░░░░░░░░░░              \n",
      "9/2014               217 ▓░░░░░░░░░░░░░░░░░░░░░░░░░         \n",
      "10/2014              181 ▓░░░░░░░░░░░░░░░░░░░░░             \n",
      "11/2014              150 ▓░░░░░░░░░░░░░░░░░                 \n",
      "12/2014              132 ▓░░░░░░░░░░░░░░░                   \n",
      "1/2015               148 ▓░░░░░░░░░░░░░░░░░                 \n",
      "2/2015               144 ▓░░░░░░░░░░░░░░░░                  \n",
      "3/2015               180 ▓░░░░░░░░░░░░░░░░░░░░              \n",
      "4/2015               175 ▓░░░░░░░░░░░░░░░░░░░░              \n",
      "5/2015               147 ▓░░░░░░░░░░░░░░░░░                 \n",
      "6/2015               154 ▓░░░░░░░░░░░░░░░░░                 \n",
      "7/2015               110 ▓░░░░░░░░░░░░                      \n",
      "8/2015               163 ▓░░░░░░░░░░░░░░░░░░                \n",
      "9/2015               227 ▓░░░░░░░░░░░░░░░░░░░░░░░░░░        \n",
      "10/2015              188 ▓░░░░░░░░░░░░░░░░░░░░░             \n",
      "11/2015              114 ▓░░░░░░░░░░░░░                     \n",
      "                         +-------+--------+--------+-------+\n",
      "                         0      75       150      225    300\n"
     ]
    }
   ],
   "source": [
    "monthyears = crimes_with_monthyears.group_by('reported_monthyear')\n",
    "monthyear_counts = monthyears.aggregate([\n",
    "    ('count', agate.Count())\n",
    "])\n",
    "monthyear_counts.print_bars('reported_monthyear', 'count', width=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, it appears we were right to suspect of 2010 and 2015. Did 2015 end magically in November? Nope. We have incomplete data. \n",
    "\n",
    "## Assignment\n",
    "\n",
    "What about Location and Building? Or Stolen and Damaged? Is there missing data? Is there wrong data? How normalized is that data? Are there outliers? What steps in Agate should you take to find out? Continue this notebook below and use tools in Agate to find out if anything is clearly wrong with the fields above -- [a whole list of descriptive statistics is here](http://agate.readthedocs.io/en/1.6.0/cookbook/statistics.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
